from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.docstore.document import Document
from ddgs import DDGS

def detect_domain(llm, query):
    """
    æª¢æŸ¥ä½¿ç”¨è€…å•é¡Œæ˜¯å¦å±¬æ–¼ã€Œå…§éƒ¨æ–‡ä»¶ã€ä¸»é¡Œï¼Œä¾‹å¦‚ç·¯å‰µã€ESGã€å ±å‘Šæ›¸ç­‰ã€‚
    å›å‚³å€¼: "internal" æˆ– "external"
    """
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹åˆ†é¡å™¨ï¼Œè² è²¬åˆ¤æ–·å•é¡Œæ˜¯å¦å±¬æ–¼ä¼æ¥­æ°¸çºŒå ±å‘Šæ›¸æˆ–å…¬å¸å…§å®¹ç›¸é—œä¸»é¡Œã€‚
    å•é¡Œè‹¥èˆ‡ä¼æ¥­ã€å ±å‘Šæ›¸ã€ESGã€ç’°ä¿ã€æ°¸çºŒã€å…¬å¸æ²»ç†ã€ç·¯å‰µæœ‰é—œï¼Œ
    å›ç­” "internal"ï¼›å¦å‰‡å›ç­” "external"ã€‚

    å•é¡Œï¼š{query}
    """
    result = llm.invoke(prompt)
    decision = result.content.strip().lower()

    if "external" in decision:
        print("ğŸŒ æ­¤å•é¡Œä¸å±¬æ–¼æ–‡ä»¶ç¯„åœ â†’ å°‡æ”¹ç”¨å¤–éƒ¨æœå°‹")
        return "external"
    else:
        print("ğŸ“„ æ­¤å•é¡Œå±¬æ–¼æ–‡ä»¶ç¯„åœ â†’ ä½¿ç”¨å…§éƒ¨æª¢ç´¢")
        return "internal"

# ============ 1ï¸âƒ£ Retrievalï¼šæ–‡ä»¶æª¢ç´¢ ============
def retrieve_documents(query):
    embeddings = OpenAIEmbeddings()
    db = FAISS.load_local("vector_store", embeddings, allow_dangerous_deserialization=True)
    retriever = db.as_retriever(search_kwargs={"k": 4})
    docs = retriever.get_relevant_documents(query)
    print(f"ğŸ“š Retrieved {len(docs)} candidate documents.")
    return docs, embeddings


# ============ 2ï¸âƒ£ Evaluationï¼šæ–‡ä»¶æ­£ç¢ºæ€§è©•ä¼° ============
def evaluate_retrieval_quality(llm, query, docs):
    """
    è«‹ LLM åˆ¤æ–·æ–‡ä»¶æ˜¯å¦ã€Œæ­£ç¢ºã€ã€Œæ¨¡ç³Šã€ã€ŒéŒ¯èª¤ã€
    """
    joined_docs = "\n\n".join([d.page_content for d in docs[:3]])
    eval_prompt = f"""
    ä½ æ˜¯ä¸€ä½è³‡æ–™å“è³ªæª¢æŸ¥å“¡ï¼Œä»»å‹™æ˜¯è©•ä¼°ä»¥ä¸‹æ–‡ä»¶æ˜¯å¦èƒ½å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚
    Question: {query}
    Documents: {joined_docs}

    è«‹å›ç­”ä¸‰æ“‡ä¸€ï¼š
    - "Correct" ï¼šæ–‡ä»¶å…§å®¹å®Œæ•´ä¸”æ˜ç¢ºå›ç­”å•é¡Œ
    - "Ambiguous" ï¼šæ–‡ä»¶å…§å®¹éƒ¨åˆ†ç›¸é—œæˆ–è³‡è¨Šä¸è¶³
    - "Incorrect" ï¼šæ–‡ä»¶èˆ‡å•é¡Œç„¡é—œæˆ–èª¤å°

    åªè¼¸å‡ºå…¶ä¸­ä¸€å€‹å­—è©ã€‚
    """
    response = llm.invoke(eval_prompt)
    decision = response.content.strip()
    print(f"ğŸ” Evaluation result â†’ {decision}")
    return decision


# ============ 3ï¸âƒ£ Knowledge Correctionï¼šçŸ¥è­˜ä¿®æ­£ ============
def refine_internal_knowledge(docs):
    """æ¨¡æ“¬å…§éƒ¨ç²¾ç…‰ï¼šæ•´åˆä¸¦éæ¿¾ PDF å…§å®¹"""
    combined_text = "\n".join([d.page_content for d in docs])
    return Document(page_content=combined_text, metadata={"source": "internal"})


def search_external_knowledge(query, max_results=5):
    """å¤–éƒ¨æœå°‹è£œå¼·"""
    print("ğŸŒ Searching external sources...")
    try:
        with DDGS() as ddgs:
            results = [
                f"{r.get('title', '')}: {r.get('body', '')}"
                for r in ddgs.text(query, max_results=max_results)
            ]
        if not results:
            print("âš ï¸ No external results found.")
            return []
        else:
            print(f"ğŸ” Found {len(results)} external results.")
            combined_text = "\n".join(results)
            return [Document(page_content=combined_text, metadata={"source": "external"})]
    except Exception as e:
        print("âŒ Search failed:", e)
        return []


def combine_knowledge(k_in, k_ex):
    """å°‡å…§éƒ¨èˆ‡å¤–éƒ¨çŸ¥è­˜æ•´åˆ"""
    combined = k_in.page_content + "\n\n" + k_ex[0].page_content
    return Document(page_content=combined, metadata={"source": "hybrid"})


# ============ 4ï¸âƒ£ Generationï¼šæœ€çµ‚ç­”æ¡ˆç”Ÿæˆ ============
def generate_answer(llm, query, context_doc):
    qa_prompt = f"""
    æ ¹æ“šä»¥ä¸‹å…§å®¹å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚
    è‹¥å…§å®¹ç„¡æ³•æä¾›ç­”æ¡ˆï¼Œè«‹èª å¯¦å›ç­”ã€Œæ–‡ä»¶ä¸­ç„¡ç›¸é—œè³‡è¨Šã€ã€‚

    Context:
    {context_doc.page_content}

    Question:
    {query}
    """
    response = llm.invoke(qa_prompt)
    return response.content.strip()


# ============ ä¸»æµç¨‹æ•´åˆ ============
def run_corrective_rag_v8(query):
    llm = ChatOpenAI(model="gpt-4o", temperature=0)

    # Step 0: Domain Detection
    domain = detect_domain(llm, query)

    if domain == "external":
    # ä¸ç”¨æª¢ç´¢ï¼Œç›´æ¥ç”¨å¤–éƒ¨æœå°‹
        k_ex = search_external_knowledge(query)
        if k_ex:
            print("\nğŸ’¬ æ­£åœ¨ç”Ÿæˆæœ€çµ‚å›ç­”ï¼ˆå¤–éƒ¨è³‡æ–™ï¼‰...")
            final_answer = generate_answer(llm, query, k_ex[0])
            print("\nğŸŸ© Final Answer:")
            print(final_answer)
            return final_answer
        else:
            return "ç„¡æ³•åœ¨å¤–éƒ¨è³‡æ–™ä¸­æ‰¾åˆ°ç­”æ¡ˆã€‚"

    # Step 1: Retrieval
    docs, embeddings = retrieve_documents(query)

    # Step 2: Evaluation
    eval_result = evaluate_retrieval_quality(llm, query, docs)

    # Step 3: Knowledge Correction
    if eval_result == "Correct":
        print("âœ… ä½¿ç”¨å…§éƒ¨çŸ¥è­˜ (k_in)")
        k_in = refine_internal_knowledge(docs)
        context = k_in

    elif eval_result == "Ambiguous":
        print("âš ï¸ æ–‡ä»¶è³‡è¨Šæ¨¡ç³Šï¼ŒåŸ·è¡Œå…§éƒ¨ç²¾ç…‰ + å¤–éƒ¨è£œå¼· (k_in + k_ex)")
        k_in = refine_internal_knowledge(docs)
        k_ex = search_external_knowledge(query)
        if k_ex:
            context = combine_knowledge(k_in, k_ex)
        else:
            context = k_in  # è‹¥æœå°‹å¤±æ•—ï¼Œåƒ…ä½¿ç”¨å…§éƒ¨çŸ¥è­˜

    elif eval_result == "Incorrect":
        print("ğŸš« æ–‡ä»¶éŒ¯èª¤ï¼Œæ”¹ç”¨å¤–éƒ¨æœå°‹ (k_ex)")
        k_ex = search_external_knowledge(query)
        if k_ex:
            context = k_ex[0]
        else:
            return "æŠ±æ­‰ï¼Œç„¡æ³•å¾å…§éƒ¨æˆ–å¤–éƒ¨æ‰¾åˆ°ç›¸é—œè³‡è¨Šã€‚"

    else:
        print("âš ï¸ è©•ä¼°çµæœä¸æ˜ï¼Œé è¨­ä½¿ç”¨å…§éƒ¨çŸ¥è­˜ã€‚")
        k_in = refine_internal_knowledge(docs)
        context = k_in

    # Step 4: Generation
    print("\nğŸ’¬ æ­£åœ¨ç”Ÿæˆæœ€çµ‚å›ç­”...")
    final_answer = generate_answer(llm, query, context)

    print("\nğŸŸ© Final Answer:")
    print(final_answer)
    return final_answer

